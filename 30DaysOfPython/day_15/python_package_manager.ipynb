{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 15: 30 Days of python programming\n",
    "\n",
    "## Python PIP - Python Package Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 70),\n",
       " ('li', 60),\n",
       " ('href', 40),\n",
       " ('class', 22),\n",
       " ('html', 20),\n",
       " ('gutenberg', 20),\n",
       " ('content', 14),\n",
       " ('div', 14),\n",
       " ('help', 14),\n",
       " ('meta', 13)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1: Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112-0.txt'\n",
    "\n",
    "# import requests\n",
    "# import webbrowser\n",
    "\n",
    "# url = 'http://www.gutenberg.org/files/1112/1112-0.txt'\n",
    "\n",
    "# webbrowser.open_new(url)\n",
    "\n",
    "\n",
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Fetch the text of Romeo and Juliet\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Clean and split the text into words\n",
    "words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Find the 10 most common words\n",
    "most_common_words = Counter(words).most_common(10)\n",
    "most_common_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight (metric) - Min: 2, Max: 11, Mean: 4.71, Median: 5.0, Std: 1.89\n",
      "Lifespan (years) - Min: 8, Max: 20, Mean: 13.75, Median: 14.0, Std: 2.40\n",
      "\n",
      "Frequency Table of Country and Breeds:\n",
      "Country\n",
      "Australia                1\n",
      "Burma                    2\n",
      "Canada                   3\n",
      "China                    1\n",
      "Cyprus                   1\n",
      "Egypt                    3\n",
      "France                   2\n",
      "Greece                   1\n",
      "Iran (Persia)            1\n",
      "Isle of Man              1\n",
      "Japan                    1\n",
      "Norway                   1\n",
      "Russia                   4\n",
      "Singapore                1\n",
      "Somalia                  1\n",
      "Thailand                 4\n",
      "Turkey                   2\n",
      "United Arab Emirates     1\n",
      "United Kingdom           8\n",
      "United States           28\n",
      "Name: Breed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "''' Q2: Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "Create a frequency table of country and breed of cats'''\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the data from the Cat API\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "response = requests.get(cats_api)\n",
    "cats_data = response.json()\n",
    "\n",
    "# Extract weight (metric) and lifespan\n",
    "weights = []\n",
    "lifespans = []\n",
    "countries = []\n",
    "breeds = []\n",
    "\n",
    "for cat in cats_data:\n",
    "    # Get weight in metric (split into min/max values)\n",
    "    weight = cat['weight']['metric'].split(\" - \")\n",
    "    weights.append([int(weight[0]), int(weight[1])])\n",
    "    \n",
    "    # Get lifespan (split into min/max values)\n",
    "    lifespan = cat['life_span'].split(\" - \")\n",
    "    lifespans.append([int(lifespan[0]), int(lifespan[1])])\n",
    "    \n",
    "    # Get country and breed\n",
    "    countries.append(cat['origin'])\n",
    "    breeds.append(cat['name'])\n",
    "\n",
    "# Calculate min, max, mean, median, and std for weights and lifespans\n",
    "weights_array = np.array(weights)\n",
    "weight_min = weights_array[:, 0].min()\n",
    "weight_max = weights_array[:, 1].max()\n",
    "weight_mean = weights_array.mean()\n",
    "weight_median = np.median(weights_array)\n",
    "weight_std = weights_array.std()\n",
    "\n",
    "lifespans_array = np.array(lifespans)\n",
    "lifespan_min = lifespans_array[:, 0].min()\n",
    "lifespan_max = lifespans_array[:, 1].max()\n",
    "lifespan_mean = lifespans_array.mean()\n",
    "lifespan_median = np.median(lifespans_array)\n",
    "lifespan_std = lifespans_array.std()\n",
    "\n",
    "# Create a frequency table of countries and breeds\n",
    "df = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Breed': breeds\n",
    "})\n",
    "\n",
    "frequency_table = df.groupby('Country')['Breed'].count()\n",
    "\n",
    "# Print results\n",
    "print(f\"Weight (metric) - Min: {weight_min}, Max: {weight_max}, Mean: {weight_mean:.2f}, Median: {weight_median}, Std: {weight_std:.2f}\")\n",
    "print(f\"Lifespan (years) - Min: {lifespan_min}, Max: {lifespan_max}, Mean: {lifespan_mean:.2f}, Median: {lifespan_median}, Std: {lifespan_std:.2f}\")\n",
    "print(\"\\nFrequency Table of Country and Breeds:\")\n",
    "print(frequency_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 largest countries by area:\n",
      "Russian Federation: 17124442.0 sq km\n",
      "Antarctica: 14000000.0 sq km\n",
      "Canada: 9984670.0 sq km\n",
      "China: 9640011.0 sq km\n",
      "United States of America: 9629091.0 sq km\n",
      "Brazil: 8515767.0 sq km\n",
      "Australia: 7692024.0 sq km\n",
      "India: 3287590.0 sq km\n",
      "Argentina: 2780400.0 sq km\n",
      "Kazakhstan: 2724900.0 sq km\n",
      "\n",
      "The 10 most spoken languages:\n",
      "English: spoken in 91 countries\n",
      "French: spoken in 45 countries\n",
      "Arabic: spoken in 25 countries\n",
      "Spanish: spoken in 24 countries\n",
      "Portuguese: spoken in 10 countries\n",
      "Russian: spoken in 8 countries\n",
      "Dutch: spoken in 8 countries\n",
      "German: spoken in 7 countries\n",
      "Chinese: spoken in 5 countries\n",
      "Serbian: spoken in 4 countries\n",
      "\n",
      "Total number of distinct languages: 123\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q3: Read the countries API and find\n",
    "the 10 largest countries\n",
    "the 10 most spoken languages\n",
    "the total number of languages in the countries API\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Fetch the data from the Countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "response = requests.get(countries_api)\n",
    "countries_data = response.json()\n",
    "\n",
    "# Find the 10 largest countries by area\n",
    "countries_by_area = sorted(countries_data, key=lambda x: x.get('area', 0), reverse=True)[:10]\n",
    "largest_countries = [(country['name'], country['area']) for country in countries_by_area]\n",
    "\n",
    "# Extract and count languages\n",
    "all_languages = []\n",
    "for country in countries_data:\n",
    "    for language in country.get('languages', []):\n",
    "        all_languages.append(language['name'])\n",
    "\n",
    "# Find the 10 most spoken languages\n",
    "language_counts = Counter(all_languages)\n",
    "most_spoken_languages = language_counts.most_common(10)\n",
    "\n",
    "# Find the total number of distinct languages\n",
    "total_languages = len(language_counts)\n",
    "\n",
    "# Print results\n",
    "print(\"The 10 largest countries by area:\")\n",
    "for country, area in largest_countries:\n",
    "    print(f\"{country}: {area} sq km\")\n",
    "\n",
    "print(\"\\nThe 10 most spoken languages:\")\n",
    "for language, count in most_spoken_languages:\n",
    "    print(f\"{language}: spoken in {count} countries\")\n",
    "\n",
    "print(f\"\\nTotal number of distinct languages: {total_languages}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI Machine Learning Repository Datasets:\n"
     ]
    }
   ],
   "source": [
    "'''Q4: UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4\n",
    "'''\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fetch the content of the UCI Machine Learning Repository\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all the dataset names in the table (usually under 'table' tags)\n",
    "table = soup.find_all('table', {'cellpadding': '3'})\n",
    "\n",
    "# Extract dataset names from the table if table is not empty\n",
    "datasets = []\n",
    "if table:\n",
    "    for row in table[0].find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        if cols:\n",
    "            dataset_name = cols[0].text.strip()\n",
    "            datasets.append(dataset_name)\n",
    "\n",
    "# Print the list of dataset names\n",
    "print(\"UCI Machine Learning Repository Datasets:\")\n",
    "for i, dataset in enumerate(datasets, 1):\n",
    "    print(f\"{i}. {dataset}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
